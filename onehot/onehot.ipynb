{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = [\n",
    "    'apple',\n",
    "    'banana',\n",
    "    'orange',\n",
    "    'lemon',\n",
    "]\n",
    "\n",
    "sellers = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "\n",
    "# 用于生成测试数据\n",
    "def generate_test_data(fruits, sellers, n, filepath):\n",
    "    fruits = np.random.choice(fruits, n)\n",
    "    sellers = np.random.choice(sellers, n)\n",
    "    prices = np.random.randint(10, 20, size=n)\n",
    "\n",
    "    fruits = np.array(fruits)[:,np.newaxis]\n",
    "    sellers = np.array(sellers)[:,np.newaxis]\n",
    "    # print(data)\n",
    "\n",
    "    # 添加列操作\n",
    "    data = np.column_stack([fruits, sellers, prices])   \n",
    "    np.savetxt(filepath, data, fmt='%s %s %s')\n",
    "\n",
    "generate_test_data(fruits, sellers, 10, './onehot/onehot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['apple', 'banana', 'lemon', 'orange']\n['A', 'C', 'D', 'E', 'F']\n"
    },
    {
     "data": {
      "text/plain": "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0., 10.],\n       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0., 17.],\n       [ 0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0., 19.],\n       [ 0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0., 17.],\n       [ 0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0., 17.],\n       [ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0., 11.],\n       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1., 17.],\n       [ 0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0., 19.],\n       [ 0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0., 10.],\n       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0., 19.]])"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt('./onehot/onehot.csv', dtype=str)\n",
    "\n",
    "# 基本思想\n",
    "# 先生成特征大小，生成具有相应大小的矩阵\n",
    "# 将生成的矩阵与原矩阵中不需要进行 onehot 处理的列进行合并\n",
    "# 从而得到一个新的矩阵\n",
    "def onehot(data, indexes):\n",
    "    # 提取不需要进行 onehot 处理的信息\n",
    "    other_feature_indexes = [i for i in range(len(data.T)) if i not in indexes]\n",
    "    # 新加入一维的信息\n",
    "    other_feature_indexes = np.array(other_feature_indexes)[:,np.newaxis]\n",
    "    other_features = np.choose(other_feature_indexes, data.T)\n",
    "    # print(other_features.T)\n",
    "\n",
    "    t_indexes = indexes\n",
    "    # 提取需要进行 onehot 处理的信息\n",
    "    indexes = np.array(indexes)[:,np.newaxis]\n",
    "    features = np.choose(indexes, data.T)\n",
    "    l_features = len(features)\n",
    "    unique_features = [np.unique(features[i]) for i in range(l_features)]\n",
    "    \n",
    "    feature_total = sum([len(unique_features[i]) for i in range(len(unique_features))])\n",
    "    # print(feature_total)\n",
    "\n",
    "    len_data = len(data)\n",
    "\n",
    "    encodings = np.zeros((len_data, feature_total))\n",
    "    # print(encodings)\n",
    "\n",
    "    offset = 0\n",
    "\n",
    "    for i in t_indexes:\n",
    "        feature = unique_features.pop(0).tolist()\n",
    "        print(feature)\n",
    "        for j in range(len(data)):\n",
    "            index = feature.index(data[j][i])\n",
    "            encodings[j][offset + index] = 1\n",
    "        offset += len(feature)\n",
    "\n",
    "    # print(encodings)\n",
    "\n",
    "    return np.column_stack((encodings, other_features.T)).astype(np.float)\n",
    "\n",
    "onehot(data, [0, 1])"
   ]
  }
 ]
}